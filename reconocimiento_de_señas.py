# -*- coding: utf-8 -*-
"""Reconocimiento de señas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CGxuK3j1b3NCno2WMlOFkJAvo1_dtbMa

# Reconocimiento de señas

## Importar librerías
"""

import numpy as np
import pandas as pd
import matplotlib
from matplotlib import pyplot as plt
import os
import tensorflow as tf
from tensorflow import keras
import random
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.layers import Input, Conv2D, Dense, MaxPooling2D
from tensorflow.keras.layers import BatchNormalization, Dropout
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
import seaborn as sns

"""## Semilla de reproducibilidad"""

# Semilla de reproducibilidad
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

"""## Conjunto de datos"""

# Ejecutar solo en colab
!gdown 1etORHD8xjCT1qXsvvfUXJoL6R_LEzyDd

# Ejecutar solo en colab
# Descomprimir conjunto de datos
!unzip -qq dataset.zip

"""### Cargar conjunto de datos"""

# Ruta donde se encuentra la carpeta de entrenamiento
ruta_entrenamiento = 'training_set'

# Entrenamiento
train_ds = keras.utils.image_dataset_from_directory(
    directory=ruta_entrenamiento,
    labels='inferred',
    label_mode='categorical',
    batch_size=32,
    image_size=(64, 64),
    color_mode='grayscale',
    validation_split=0.2,
    seed = SEED,
    shuffle=True,
    subset='training')

# Validación
val_ds = keras.utils.image_dataset_from_directory(
    directory=ruta_entrenamiento,
    labels='inferred',
    label_mode='categorical',
    batch_size=32,
    image_size=(64, 64),
    color_mode='grayscale',
    validation_split=0.2,
    seed = SEED,
    shuffle=True,
    subset='validation')

class_names = train_ds.class_names
print(f'Class names: {class_names}')

input_shape = (64, 64, 1)
num_classes = len(class_names)
print(f'Tamaño de imagen: {input_shape}')
print(f'Número de classes: {num_classes}')

"""### Distribución de clases"""

def obtener_frequencias_clases(dataset):
    # Extraer etiquetas del conjunto de datos
    labels = []
    for _, label in dataset:
        labels.extend(label.numpy())

    conteo_clases = np.sum(labels, axis=0)
    return conteo_clases

conteo_clases = obtener_frequencias_clases(train_ds)
print(conteo_clases)

plt.bar(list(range(len(class_names))), conteo_clases)
plt.title("Distribución de clases")
plt.xticks(range(len(class_names)), class_names)#, rotation=45)
plt.ylabel('Frecuencia')
plt.show()

conteo_clases_val = obtener_frequencias_clases(val_ds)
print(conteo_clases_val)

"""#### Lote de ejemplo"""

imagen, etiquetas = next(iter(train_ds))

print('Batch')
print('-'*6)
print(f'Tamaño de imagen: {imagen.shape}')
print(f'Tamaño de etiquetas: {etiquetas.shape}')

"""### Visualización de datos"""

def visualizar_imagenes(dataset):
    imagenes, etiquetas = next(iter(dataset)) # Extraer 1 lote del dataset
    imagenes = imagenes.numpy()
    etiquetas = etiquetas.numpy()

    fig = plt.figure(figsize=(8, 8))
    for i in range(25):
        ax = fig.add_subplot(5, 5, i+1, xticks=[], yticks=[])
        if imagenes.shape[-1] == 1:
            ax.imshow(imagenes[i], cmap='gray')
        else:
            ax.imshow(imagenes[i])
        ax.set_title(f"Etiqueta: {class_names[np.array(etiquetas[i]).argmax()]}")
    plt.tight_layout()
    plt.show()

visualizar_imagenes(train_ds)

"""## Preprocesamiento

### Reescalado
"""

reescalar = layers.Rescaling(1./255)

"""### Aumento de datos"""

aumento_datos = tf.keras.Sequential([
    #layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1, 0.1),
    #layers.Resizing(height=input_shape[0], width=input_shape[1])
])

def visualizar_imagenes_aumento_datos(dataset, transformaciones):
    imagenes, etiquetas = next(iter(dataset)) # Extraer 1 lote del dataset
    imagenes = imagenes.numpy()
    etiquetas = etiquetas.numpy()

    imagenes_transformadas = transformaciones(imagenes)
    fig = plt.figure(figsize=(8, 8))
    for i in range(25):
        ax = fig.add_subplot(5, 5, i+1, xticks=[], yticks=[])
        if imagenes.shape[-1] == 1:
            ax.imshow(imagenes_transformadas[i], cmap='gray')
        else:
            ax.imshow(imagenes_transformadas[i])
        ax.set_title(f"Etiqueta: {class_names[np.array(etiquetas[i]).argmax()]}")
    plt.tight_layout()
    plt.show()
visualizar_imagenes_aumento_datos(train_ds, aumento_datos)

"""### Transformaciones

"""

transformaciones_data = tf.keras.Sequential([
    reescalar,
    aumento_datos
])

"""### Modelo"""

def crear_modelo_cnn(input_shape, output_shape, transformaciones):
    model = models.Sequential([
        Input(shape=input_shape), #64x64x1
        transformaciones, #reescalando + aumento de datos
        Conv2D(filters=16, kernel_size=3, strides=1, padding="valid", activation='relu'), #sigmoid, tanh
        MaxPooling2D(pool_size=2, strides=2),

        Conv2D(filters=32, kernel_size=3, strides=1, padding="valid", activation='relu'),
        MaxPooling2D(2, 2),

        Conv2D(filters=64, kernel_size=3, strides=1, padding="valid", activation='relu'),
        MaxPooling2D(2, 2),

        Conv2D(filters=128, kernel_size=3, strides=1, padding="valid", activation='relu'),
        MaxPooling2D(2, 2),

        layers.GlobalAveragePooling2D(),
        #layers.Flatten(),
        #layers.Dense(128, activation='relu'),
        #layers.Dropout(0.5),
        layers.Dense(output_shape, activation='softmax') # fully connected
    ])
    return model

modelo = crear_modelo_cnn(input_shape, num_classes, transformaciones_data)
modelo.summary()





"""## Entrenamiento"""

def crear_callbacks(checkpoint_filepath):

    # Definir el callback ModelCheckpoint ajustado para monitorear 'val_accuracy'
    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
        filepath=checkpoint_filepath,
        save_weights_only=True,
        monitor='val_loss',  # Monitorea la precisión de entrenamiento
        save_best_only=True,
        verbose=1
    )

    return [model_checkpoint_callback]

keras.utils.set_random_seed(SEED)

# Hiperparámetros
num_epochs = 20
learning_rate = 1e-3

modelo = crear_modelo_cnn(input_shape, num_classes, transformaciones_data)

# Callbacks
checkpoint_filepath = 'CNN_checkpoint.h5'
callbacks = crear_callbacks(checkpoint_filepath)

# Compilar el modelo
modelo.compile(optimizer=optimizers.Adam(learning_rate=learning_rate),
              loss='categorical_crossentropy',
              metrics=['accuracy', tf.keras.metrics.F1Score(average='macro')])

# Entrenar el modelo con los callbacks ajustados para monitorear métricas de entrenamiento
train_info = modelo.fit(
    train_ds,
    epochs=num_epochs,
    validation_data=val_ds,
    callbacks = callbacks
)

train_info.history.keys()

"""##  Curvas de aprendizaje

### Pérdida por época
"""

def visualizar_curva_aprendizaje(train_info, report, xlabel='Épocas', ylabel='Pérdida', title=''):
    train_loss = train_info.history[report]
    val_loss = train_info.history['val_' + report]
    epochs = range(1, len(train_loss) + 1)

    # Mostrar curva
    plt.figure(figsize=(8, 5))
    plt.plot(epochs, train_loss, 'o--', label='Entrenamiento')
    plt.plot(epochs, val_loss, 'o--', label='Validación')
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    locator = matplotlib.ticker.MultipleLocator(2)
    plt.gca().xaxis.set_major_locator(locator)
    formatter = matplotlib.ticker.StrMethodFormatter("{x:.0f}")
    plt.gca().xaxis.set_major_formatter(formatter)

    #plt.xticks(epochs)
    plt.title(title)
    plt.legend()
    plt.grid()
    plt.show()

visualizar_curva_aprendizaje(train_info, 'loss', xlabel='Épocas', ylabel='Pérdida', title='Error de Entrenamiento y Validación')

"""### Accuracy por época"""

visualizar_curva_aprendizaje(train_info, 'accuracy', xlabel='Épocas', ylabel='Accuracy', title='Accuracy de Entrenamiento y Validación')

"""### F1-Score por época"""

visualizar_curva_aprendizaje(train_info, 'f1_score', xlabel='Épocas', ylabel='F1-Score', title='F1-score de Entrenamiento y Validación')

"""## Resultados

### Cargar mejor modelo
"""

# Cargar pesos del mejor modelo
modelo.load_weights('CNN_checkpoint.h5')

"""### Resultados de validación"""

def obtener_predicciones_etiquetas(modelo, dataset):
    num_samples = len(dataset)
    # Crear matrices para almacenar las etiquetas verdaderas y las etiquetas predichas
    true_labels = []
    predicted_labels = []
    for i, (imagenes, label) in enumerate(dataset):
        predicciones = modelo.predict(imagenes, verbose=0)
        # Almacenar resultados
        true_labels.append(label.numpy().argmax(1))
        predicted_labels.append(predicciones.argmax(1))
    return np.concatenate(true_labels), np.concatenate(predicted_labels)

etiquetas_val, predicciones_val = obtener_predicciones_etiquetas(modelo, val_ds)

print(class_names)

"""#### Resultados de clasificación"""

print(classification_report(etiquetas_val, predicciones_val, target_names=class_names, digits=4))

"""#### Matriz de confusión"""

def visualizar_matriz_confusion(etiquetas_reales, etiquetas_predichas, class_names, titulo='Matriz de confusión'):
    # Calcular matriz de confusión
    cm = confusion_matrix(etiquetas_reales, etiquetas_predichas)

    # Visualizar matriz de confusión
    plt.figure(figsize=(12, 12))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names) #cbar=False
    plt.title(titulo)
    plt.xlabel('Predicción')
    plt.ylabel('Real')
    plt.show()

visualizar_matriz_confusion(etiquetas_val, predicciones_val, class_names, 'Matriz de confusión de validación')

"""### Resultados de prueba

#### Leer dato de prueba
"""

# Ruta donde se encuentra la carpeta de prueba
ruta_prueba = 'test_set'

# Prueba
test_ds = keras.utils.image_dataset_from_directory(
    directory=ruta_prueba,
    labels='inferred',
    label_mode='categorical',
    batch_size=32,
    image_size=(64, 64),
    color_mode='grayscale',
    seed = SEED,
    shuffle=False)

def obtener_etiquetas(dataset):
    labels = []
    for _, label in dataset:
        labels.append(label.numpy().argmax(1))
    return np.concatenate(labels)

etiquetas_test = obtener_etiquetas(test_ds)

probabilidades_test = modelo.predict(test_ds)

predicciones_test = probabilidades_test.argmax(1)

print(class_names)

"""#### Resultados de clasificación"""

print(classification_report(etiquetas_test, predicciones_test, target_names=class_names, digits=4))

"""#### Matriz de confusión"""

visualizar_matriz_confusion(etiquetas_test, predicciones_test, class_names, 'Matriz de confusión de prueba')

#errores_predicciones = np.where(~(etiquetas_test == predicciones_test))[0]

"""### Errores de clasificación"""

input_shape = (64, 64, 1)
class_names = test_ds.class_names
num_classes = len(class_names)
modelo = crear_modelo_cnn(input_shape, num_classes, transformaciones_data)
modelo.load_weights('CNN_checkpoint.h5')

def obtener_etiquetas(dataset):
    labels = []
    for _, label in dataset:
        labels.append(label.numpy().argmax(1))
    return np.concatenate(labels)

etiquetas_test = obtener_etiquetas(test_ds)
probabilidades_test = modelo.predict(test_ds)
predicciones_test = probabilidades_test.argmax(1)

errores_predicciones = np.where(~(etiquetas_test == predicciones_test))[0]

errores_predicciones

etiquetas_test[errores_predicciones]

errores_imagenes = []
index = 0
for imagenes, etiquetas in test_ds:
    for i in range(len(imagenes)):
        if index in errores_predicciones:
            errores_imagenes.append(imagenes[i].numpy())
        index += 1

def visualizar_imagenes_errores(imagenes, predicciones, etiquetas, class_names):
    fig = plt.figure(figsize=(8, 8))
    for i in range(20):
        ax = fig.add_subplot(5, 4, i+1, xticks=[], yticks=[])
        if imagenes[i].shape[-1] == 1:
            ax.imshow(imagenes[i], cmap='gray')
        else:
            ax.imshow(imagenes[i])
        ax.set_title(f"Real: {class_names[np.array(etiquetas[i])]} \nPredicción: {class_names[predicciones[i]]}")
    plt.tight_layout()
    plt.show()

visualizar_imagenes_errores(errores_imagenes, predicciones_test[errores_predicciones], etiquetas_test[errores_predicciones], class_names)

